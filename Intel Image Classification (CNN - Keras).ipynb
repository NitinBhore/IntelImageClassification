{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea7f96d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import tarfile\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor,ToPILImage\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from skimage.io import imread, imshow\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import keras.callbacks\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import random\n",
    "from keras.applications import vgg16\n",
    "from keras.preprocessing import image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2211dbc1",
   "metadata": {},
   "source": [
    "# Label and load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5bda579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'C:/Users/Nitin/Downloads/other/image/Intel Image Classification/seg_train'\n",
    "test_dir = 'C:/Users/Nitin/Downloads/other/image/Intel Image Classification/seg_test'\n",
    "pred_dir = 'C:/Users/Nitin/Downloads/other/image/Intel Image Classification/seg_pred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89a17b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class names with labels:  {'buildings': 0, 'forest': 1, 'glacier': 2, 'mountain': 3, 'sea': 4, 'street': 5}\n",
      "number of classes:  6\n"
     ]
    }
   ],
   "source": [
    "# assign class labels\n",
    "class_names = ['buildings','forest','glacier','mountain','sea','street']\n",
    "class_labels = {class_name:i for i, class_name in enumerate(class_names)}\n",
    "print(\"class names with labels: \",class_labels)\n",
    "\n",
    "number_classes = len(class_names)\n",
    "print(\"number of classes: \", number_classes)\n",
    "\n",
    "IMAGE_SIZE = (150,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e99b8160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buildings : 2191\n",
      "forest : 2271\n",
      "glacier : 2404\n",
      "mountain : 2512\n",
      "sea : 2274\n",
      "street : 2382\n"
     ]
    }
   ],
   "source": [
    "# usecase of os.listdir and os.path.join functions\n",
    "for folder in os.listdir(train_dir):\n",
    "    files_path = []\n",
    "    for file in os.listdir(os.path.join(train_dir,folder)):\n",
    "        files_path.append(file)\n",
    "    print(folder,\":\", len(files_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1652fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define load_dataset function to load dataset with labels\n",
    "def load_dataset():\n",
    "    # create list of datasets\n",
    "    datasets = [train_dir, test_dir]\n",
    "    output = []\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        \n",
    "        images1 = []\n",
    "        labels1 = []\n",
    "        print(f\"loading {dataset}\")\n",
    "        \n",
    "        for folder in os.listdir(dataset):\n",
    "            # assign labels to each folder images\n",
    "            label = class_labels[folder]\n",
    "            for file in tqdm(os.listdir(os.path.join(dataset,folder))):\n",
    "                image_path = os.path.join(os.path.join(dataset, folder), file)\n",
    "                # read the image files stored in image_path\n",
    "                image_file = cv2.imread(image_path)\n",
    "                image_file = cv2.cvtColor(image_file, cv2.COLOR_BGR2RGB)\n",
    "                image_file = cv2.resize(image_file, IMAGE_SIZE)\n",
    "                \n",
    "                images1.append(image_file)\n",
    "                labels1.append(label)\n",
    "                \n",
    "        # convert the images and labels list to numpy array\n",
    "        images1 = np.array(images1, dtype = 'float32')\n",
    "        labels1 = np.array(labels1, dtype = 'int32')\n",
    "        \n",
    "        output.append((images1, labels1))\n",
    "        print(\"Images file have been loaded\")\n",
    "                \n",
    "    return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a611e191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading C:/Users/Nitin/Downloads/other/image/Intel Image Classification/seg_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2191/2191 [00:01<00:00, 1810.19it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2271/2271 [00:01<00:00, 1683.46it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2404/2404 [00:01<00:00, 1856.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2512/2512 [00:01<00:00, 1932.31it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2274/2274 [00:01<00:00, 1933.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2382/2382 [00:01<00:00, 1822.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images file have been loaded\n",
      "loading C:/Users/Nitin/Downloads/other/image/Intel Image Classification/seg_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 437/437 [00:00<00:00, 1618.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 474/474 [00:00<00:00, 1686.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 553/553 [00:00<00:00, 1933.55it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 525/525 [00:00<00:00, 1902.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 510/510 [00:00<00:00, 1868.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 501/501 [00:00<00:00, 1834.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images file have been loaded\n"
     ]
    }
   ],
   "source": [
    "# load the data using above functions\n",
    "((train_images, train_labels), (test_images, test_labels)) = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e658e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size:\n",
      " Images: 14034 , Labels 14034\n",
      "test dataset size:\n",
      " Images: 3000 , Labels 3000\n"
     ]
    }
   ],
   "source": [
    "print(\"train dataset size:\\n\", \"Images:\",len(train_images), \", Labels\", len(train_labels))\n",
    "print(\"test dataset size:\\n\", \"Images:\",len(test_images), \", Labels\", len(test_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f48c3d",
   "metadata": {},
   "source": [
    "# Pre-process and explore image datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7294e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of image dataset is 4D tensors\n",
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96f8744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the train nad test datasets\n",
    "train_images, train_labels = shuffle(train_images, train_labels, random_state=25)\n",
    "test_images, test_labels = shuffle(test_images, test_labels, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d73ce0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping 6000 data instances for training and testing our model\n",
    "train_images = train_images[:6000]\n",
    "train_labels = train_labels[:6000]\n",
    "\n",
    "test_images = test_images[:1400]\n",
    "test_labels = test_labels[:1400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066c6ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see proportion of classes in train and test dataset\n",
    "def proportion_labels(labels, dataset):\n",
    "    series = pd.DataFrame(labels).reset_index()\n",
    "    series.rename(columns = {0:'labels'}, inplace=True)\n",
    "    final_s = series.groupby('labels').count().reset_index()                                          \n",
    "    ticks1= [key for key in class_labels.keys()]\n",
    "    \n",
    "    # plot the pie chart and bar graph of labels\n",
    "    plt.figure(figsize=(15,6))\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.bar(np.array(final_s['labels']), np.array(final_s['index']))\n",
    "    plt.xticks(ticks=np.array(final_s['labels']), labels=ticks1, fontsize=12, fontweight='bold')\n",
    "    plt.yticks(fontsize=12, fontweight='bold')\n",
    "    plt.grid(visible=True)\n",
    "    plt.title(\"Number of images per class\", size=14, weight='bold')\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.pie(final_s['index'].ravel(),\n",
    "            labels=ticks1,\n",
    "            autopct='%1.2f%%',\n",
    "            textprops={'fontweight':'bold'}\n",
    "           )\n",
    "    plt.title(\"proportion of classes\", size=14, weight='bold')\n",
    "    \n",
    "    plt.suptitle(f\"Proportion of {dataset} data\", size=20, weight='bold')\n",
    "    plt.show()\n",
    "    \n",
    "    return final_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47534809",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_s = proportion_labels(train_labels, \"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57de4c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_d = proportion_labels(test_labels, \"test\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "22a9a4f2",
   "metadata": {},
   "source": [
    "Observation:\n",
    "Our both training and test datasets are more or less equally distributed as we shuffled the dataset after loading and labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3570c0a3",
   "metadata": {},
   "source": [
    "# Good practice: scale the data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab18f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the images dataset\n",
    "trn_images_norm = train_images/255.0\n",
    "tst_images_norm = test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840e5092",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot 3*5 visualization of images\n",
    "plt.figure(figsize=(15,9))\n",
    "for idx, label in enumerate(train_labels[:20]):\n",
    "    plt.subplot(4,5, idx+1)\n",
    "    plt.imshow(trn_images_norm[idx])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(f'image class: {class_names[label]}')   \n",
    "    \n",
    "plt.suptitle(f'Image samples from training data', size=20, weight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5854b35",
   "metadata": {},
   "source": [
    "# Deep neural network model using CNN layers\n",
    "\n",
    "Feature extraction process of CNN\n",
    "The fundamental difference between a densely connected layer and a convolution layer is that, Dense layers learn global patterns in their input feature space, whereas convolution layers learn local patterns by small windows of feature map.\n",
    "\n",
    "Feature extraction performed by CNN consists of 3 basic operations.\n",
    "\n",
    "Filter: an image for a perticular feature (Convolution)\n",
    "Detect: feature within the filtered image (ReLU)\n",
    "Condense: image to enhance the features (Maxpooling)\n",
    "Ref: Deep learning with Python by Francois Chollet, Kaggle learn's Convolution and relu chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6e033f",
   "metadata": {},
   "source": [
    "# CNN2D layer arguments:\n",
    "\n",
    "tf.keras.layers.Conv2D( filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), groups=1, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs )\n",
    "\n",
    "Important arguments and their description\n",
    "\n",
    "filters - Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution)\n",
    "\n",
    "kernel_size - An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions\n",
    "\n",
    "strides - An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.\n",
    "\n",
    "padding - one of \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding with zeros evenly to the left/right or up/down of the input. When padding=\"same\" and strides=1, the output has the same size as the input.\n",
    "\n",
    "activation - Activation function to use. If you don't specify anything, no activation is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c28a9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architecture of first keras model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(150,150,3)))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "model.add(layers.Conv2D(32, kernel_size=(3,3), activation='relu'))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "model.add(layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "model.add(layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "model.add(layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(6, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a581daf0",
   "metadata": {},
   "source": [
    "# Then, we can compile it with some parameters such as:\n",
    "\n",
    "Optimizer: adam = RMSProp + Momentum. What is Momentum and RMSProp ?\n",
    "Momentum = takes into account past gradient to have a better update.\n",
    "RMSProp = exponentially weighted average of the squares of past gradients.\n",
    "Loss function: we use sparse categorical crossentropy for classification, each images belongs to one class only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae263e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels to categorical \n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# compile the model with 'adam' optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy']\n",
    "             )\n",
    "\n",
    "# SETUP A EARLY STOPPING CALL and model check point API\n",
    "earlystopping = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                              patience=5,\n",
    "                                              verbose=1,\n",
    "                                              mode='min'\n",
    "                                              )\n",
    "checkpointer = ModelCheckpoint(filepath='bestvalue', verbose=0, save_best_only=True)\n",
    "callback_list = [checkpointer, earlystopping]\n",
    "\n",
    "# fit model to the data\n",
    "history = model.fit(trn_images_norm, train_labels, batch_size=128, epochs=15, validation_data=(tst_images_norm, test_labels),\n",
    "                   callbacks=callback_list)\n",
    "\n",
    "# evalute the model\n",
    "test_loss, test_acc = model.evaluate(tst_images_norm, test_labels, verbose=0)\n",
    "print(\"test loss and accuracy:\", test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84e2f84",
   "metadata": {},
   "source": [
    "# Note:\n",
    "\n",
    "With 15 epochs and adam optimizer our test dataset accuracy comes around at 76-79% while our train accuracy stood at 80% at max.\n",
    "\n",
    "This is the case of underfitting. to overcome underfitting, we need more deeper NN model to find highest accuracy. also we need to check where the error lies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e91ba4",
   "metadata": {},
   "source": [
    "# Plot the Loss and accuracy curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104e0951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(history):\n",
    "\n",
    "    # create object of arrays of accuracy and loss\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    # number of epochs in our model\n",
    "    epochs = range(1 ,len(acc) + 1)\n",
    "    \n",
    "    # call matplolib figure object and plot loss and accuracy curves\n",
    "    plt.figure(figsize=(15,6))\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title(\"Training and validation accuracy\", fontsize=15)\n",
    "    plt.xlabel('epochs', fontsize=14)\n",
    "    plt.ylabel(\"accuracy\", fontsize=14)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title(\"Training and validation loss\", fontsize=15)\n",
    "    plt.xlabel('epochs', fontsize=14)\n",
    "    plt.ylabel(\"loss\", fontsize=14)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# call the function to plot the curves\n",
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf67ff1",
   "metadata": {},
   "source": [
    "# Observation:\n",
    "We can learn that image index numbers 6 and 7 are not predicted correctly from our prediction dataset. we will do error dataset on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab13f009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "CM = confusion_matrix(test_labels, pred_labels)\n",
    "ax = plt.axes()\n",
    "sn.heatmap(CM, annot=True, \n",
    "           annot_kws={\"size\": 10}, \n",
    "           xticklabels=class_names, \n",
    "           yticklabels=class_names, ax = ax)\n",
    "ax.set_title('Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115e70b1",
   "metadata": {},
   "source": [
    "# Error analysis on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f2942e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on validation data to check the errors\n",
    "preds = model.predict(tst_images_norm)\n",
    "print(\"Shape of the prediction indexs\", preds.shape)\n",
    "\n",
    "# apply argmax function over a rows to find \n",
    "predictions_f = np.argmax(preds, axis=1)\n",
    "print(\"Shape of predicitons vector:\", predictions_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0009ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categorical test labels to numpy array of 1 dim\n",
    "test_list = []\n",
    "for i in test_labels:\n",
    "    index1 = list(np.argwhere(i).reshape(1))[0]\n",
    "    test_list.append(index1)\n",
    "\n",
    "test_array = np.array(test_list)\n",
    "print(\"shape of actual test array:\", test_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a212c30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mislabled_images(class_names, test_images, test_labels, predicted_labels):\n",
    "    # find the  mislabeled images using np.where and return array of mislabled images\n",
    "    mislabels = (test_labels == predicted_labels)\n",
    "    mislabels_index = np.array(np.where(mislabels == False)).ravel()\n",
    "    mislables_images = test_images[mislabels_index]\n",
    "    mislables_labels = predicted_labels[mislabels_index]\n",
    "    \n",
    "    print(\"Number of total mislabeled images\", mislables_labels.shape)\n",
    "    \n",
    "    # plot the 20 mislabeled images\n",
    "    plt.figure(figsize=(15,9))\n",
    "    for idx, label in enumerate(mislables_labels[:20]):\n",
    "        plt.subplot(4,5, idx+1)\n",
    "        plt.imshow(mislables_images[idx])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(f'Predicted class: {class_names[label]}')   \n",
    "    \n",
    "        plt.suptitle(f'Mislabeled images from test data', size=20, weight='bold')\n",
    "    plt.show()  \n",
    "    return mislables_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b032aef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mislables_labels = mislabled_images(class_names, tst_images_norm, test_array, predictions_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e784fff",
   "metadata": {},
   "source": [
    "# Observations:\n",
    "\n",
    "Model confuses between street with buildings and actual building class\n",
    "\n",
    "Model confuses sea/glacier with mountains and actual mountains. model classifies them as mountains rathar than sea or glacier\n",
    "\n",
    "It seems reasonable by seeing these variations that why these images are mislabeled. to mitigate this we have to build more deeper NN model with pre-trained base and increse accuracy of classification.\n",
    "\n",
    "We won't do data augmentation in this problem, as these are the natural scenary images rather than specifics object images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78075b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model in H5 format\n",
    "#model.save('image_classifier_cnn1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0f50e0",
   "metadata": {},
   "source": [
    "# Prediction on unseen image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b286214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the prediction data and predict class on unseen data\n",
    "def getImagePaths(path):\n",
    "    image_names = []\n",
    "    for dirname, _, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            fullpath = os.path.join(dirname, filename)\n",
    "            image_names.append(fullpath)\n",
    "    return image_names\n",
    "\n",
    "images_paths = getImagePaths(pred_dir)\n",
    "print(\"images_paths: \",len(images_paths))\n",
    "\n",
    "# images path list to numpy array using cv2.imread module\n",
    "file_array = []\n",
    "\n",
    "for file in images_paths[:9]:\n",
    "    files = cv2.imread(file)/255.0 \n",
    "    file_array.append(files)\n",
    "    \n",
    "file_array = np.array(file_array)\n",
    "# vector of prected probability of each class by our model\n",
    "predictions = model.predict(file_array)\n",
    "print(\"shape: \", predictions.shape)\n",
    "\n",
    "# prediciton of 'index 0'image from 'preds_dir' image directory\n",
    "preds_index = np.argmax(predictions, axis=1)\n",
    "preds_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb9de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample prediciton on unseen data using model\n",
    "plt.figure(figsize=(12,9))\n",
    "\n",
    "for idx, i in enumerate(preds_index):\n",
    "    plt.subplot(3,3, idx+1)\n",
    "    plt.imshow(file_array[idx])\n",
    "    plt.title(f\"prediction of image: {class_names[i]}\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "plt.suptitle(\"Samples predictions of model on unseen data\", size=20, weight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef466cff",
   "metadata": {},
   "source": [
    "# confusion_matrix\n",
    "CM = confusion_matrix(test_labels, preds_index)\n",
    "ax = plt.axes()\n",
    "sn.heatmap(CM, annot=True, \n",
    "           annot_kws={\"size\": 10}, \n",
    "           xticklabels=class_names, \n",
    "           yticklabels=class_names, ax = ax)\n",
    "ax.set_title('Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481f6759",
   "metadata": {},
   "source": [
    "# Predict labels of unseen data and classify them into their respective class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4db36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_classifier(images_paths, class_names):\n",
    "    file_array2 = []\n",
    "    \n",
    "    for file2 in images_paths:\n",
    "        files2 = cv2.imread(file2)/255.0 \n",
    "        file_array2.append(files2)\n",
    "        \n",
    "    file_array2 = np.array(file_array2)\n",
    "    \n",
    "    # run thorought the convolutional base and then model2\n",
    "    img_arr = conv_base.predict(file_array2)\n",
    "    \n",
    "    # run img_arr of shape (9,4,4,512) through model2\n",
    "    img_pred = model2.predict(img_arr)\n",
    "    img_predf = np.argmax(img_pred, axis=1)\n",
    "    print(\"shape of the predicted array:\", img_predf.shape)\n",
    "    \n",
    "    # plot the 20 unseen images and predicted class\n",
    "    plt.figure(figsize=(17,13))\n",
    "    \n",
    "    for idx, i in enumerate(img_predf):\n",
    "        plt.subplot(4,5, idx+1)\n",
    "        plt.imshow(file_array2[idx])\n",
    "        plt.title(f\"prediction of image: {class_names[i]}\")\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    \n",
    "    plt.suptitle(\"Samples predicition of model2 on unseen data\", size=20, weight='bold')\n",
    "    plt.show()\n",
    "    \n",
    "images_classifier(images_paths[:20], class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7f607f",
   "metadata": {},
   "source": [
    "# Observation:\n",
    "\n",
    "Here, we can see how model2 using vgg16 as a base performed really well than previous model. model2 could correctly classify every image of first 20 samples.\n",
    "\n",
    "It improved from previous errors of buildings/street and mountain/glacier confusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fa4ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model2 with h5 extension\n",
    "#model2.save(\"image_classifier_cnn2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d234280c",
   "metadata": {},
   "source": [
    "# Conclusions:\n",
    "\n",
    "In this notebook, We built 2 Deep Neural network models using CNN layers.\n",
    "\n",
    "Our first model's accuracy was at around 78% and our second model's accuracy improved to 87% which is significant in our problem.\n",
    "\n",
    "We saw workings of CNN layer with key parameters and their description. we also learned about VGG16 pretrained base and its architecture.\n",
    "Finally, we visualized intermediate activations of each layer of model1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daf71ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.kaggle.com/code/avikumart/computervision-intel-image-classification-project\n",
    "https://www.kaggle.com/code/vincee/intel-image-classification-cnn-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43746a87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img",
   "language": "python",
   "name": "img"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
